{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f616ae65-14e4-426e-ade4-36c0a6c5f118",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### RNN Model for churn or next event prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7dbdb685-107a-4fef-a97e-4551a44cbbd5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import signal\n",
    "\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "from customer_analysis.pipelines import RNNPipeline\n",
    "from customer_analysis.utils.nn_datasets import EventSequenceDataPreparation\n",
    "from customer_analysis.utils.visualization import plot_rnn_attention_heatmap\n",
    "from customer_analysis.utils.data_processing import read_rnn_attention_data, \\\n",
    "    get_sequences_above_weights_threshold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module='distutils')\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning,\n",
    "                        module='_distutils_hack')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ee784776-1d30-4f9a-a552-2e9b3de4f990",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# define task - eg. to predict churn or next event on below data\n",
    "# NOTE: change also in config.json at \"task\" param.\n",
    "churn = False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "007efa04-5120-4d8c-8d70-27ff5eadfd1d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Prepare BiGQuery [GA4] data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "39000552-33a6-4adc-94ce-fc10925a32b4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "file_1 = \"../data/bq-results-20230807_100k_20210130.json\"\n",
    "df1 = pd.read_json(file_1, lines=True)\n",
    "\n",
    "file_2 = \"../data/bq-results-20230807_100k_20210131.json\"\n",
    "df2 = pd.read_json(file_2, lines=True)\n",
    "\n",
    "df = pd.concat([df1, df2], axis=0, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare mapping dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b169227e-db4c-4be1-b527-1458f13eaafb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Prepare events dictionaries + padded value\n",
    "unique_events = df['event_name'].unique()\n",
    "idx2even = {i: event for i, event in enumerate(list(unique_events))}\n",
    "idx2even[len(idx2even)] = '<PAD>'\n",
    "\n",
    "even2idx = {value: key for key, value in idx2even.items()}\n",
    "idx2churn = {0: 'Not_Churned', 1: 'Churned'}\n",
    "\n",
    "idx2even\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'event_name': 'events_sequence'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare data for next event prediction - rather short sequences of events (per session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "18bf15dd-fc29-4b48-8572-acb79ded64fd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Extract session ID from the data\n",
    "def get_session_id(event_params):\n",
    "    for param in event_params:\n",
    "        if param['key'] == 'ga_session_id':\n",
    "            return param['value']['int_value']\n",
    "    return None\n",
    "\n",
    "\n",
    "df['session_id'] = df['event_params'].apply(get_session_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group data -> all events per user session (not for churn prediction)\n",
    "grouped_session_df = pd.DataFrame(df.sort_values(\n",
    "    ['user_pseudo_id', 'event_timestamp'])\n",
    "    .groupby(['user_pseudo_id', 'session_id'])['events_sequence'].apply(list))\n",
    "grouped_session_df.reset_index(inplace=True)\n",
    "\n",
    "grouped_session_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare data for churn prediction - long sequences of events"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9701f54a-7d6a-4da3-9df6-abf9dfc0fc4d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Below approach for churn defninition is based on:\n",
    "- https://github.com/GoogleCloudPlatform/analytics-componentized-patterns/blob/master/gaming/propensity-model/bqml/bqml_ga4_gaming_propensity_to_churn.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b19467c9-1b70-4369-9765-8c4d0ee5d632",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Define churn per user\n",
    "firstlasttouch = df.groupby('user_pseudo_id').agg(\n",
    "    {'event_timestamp': ['min', 'max']})\n",
    "firstlasttouch.columns = ['user_first_engagement', 'user_last_engagement']\n",
    "\n",
    "returningusers = firstlasttouch.assign(\n",
    "    ts_24hr_after_first_engagement=lambda x: x['user_first_engagement'] +\n",
    "    (3600000000 * 24),   # * 24h\n",
    "    churned=lambda x: (x['user_last_engagement'] <\n",
    "                       x['ts_24hr_after_first_engagement']).astype(int),\n",
    "    bounced=lambda x: (x['user_last_engagement'] <=\n",
    "                       x['user_first_engagement'] + 60000000 * 10).astype(int)  # * 10min\n",
    ")\n",
    "\n",
    "churned_idx = returningusers[(returningusers['bounced'] == 0) &\n",
    "                             (returningusers['churned'] == 1)].index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "db7e3a35-f180-4438-96cf-17b4e7a22744",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Assign churn to previously determined user IDs\n",
    "df['is_churned'] = df['user_pseudo_id']\\\n",
    "    .apply(lambda x: x in churned_idx).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dac363da-1273-42cf-ba48-61204be54d2b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Group data -> all events per one user + churn\n",
    "grouped_churn_df = pd.DataFrame(df.sort_values(\n",
    "    ['user_pseudo_id', 'event_timestamp'])\n",
    "    .groupby(['user_pseudo_id', 'is_churned'])['events_sequence'].apply(list))\n",
    "grouped_churn_df.reset_index(inplace=True)\n",
    "\n",
    "grouped_churn_df.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assign data to final df - based on 'task'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fd05be59-0940-43d6-850e-a084e53ee278",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Based on 'churn' boolean, determin data to use with RNN model\n",
    "grouped_df = grouped_churn_df if churn else grouped_session_df\n",
    "\n",
    "# Exclude sequences with just one event:\n",
    "grouped_df = grouped_df[grouped_df['events_sequence'].apply(len) > 1]\n",
    "\n",
    "grouped_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exclude longest event sequence and shuffle the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths = grouped_df['events_sequence'].apply(len)\n",
    "top_10_lengths = lengths.nlargest(10)\n",
    "top_10_lengths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop longest sequence <- because of padding and for computation time\n",
    "grouped_df.drop(index=[top_10_lengths.index[0]], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths = grouped_df['events_sequence'].apply(len)\n",
    "top_10_lengths = lengths.nlargest(10)\n",
    "top_10_lengths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df = grouped_df.sample(frac=1, random_state=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tensor_dataset = EventSequenceDataPreparation(padding_value=even2idx['<PAD>'],\n",
    "                                                    event2idx=even2idx,\n",
    "                                                    input_df=grouped_df,\n",
    "                                                    sequence_column='events_sequence',\n",
    "                                                    target_column='is_churned' if churn else None,\n",
    "                                                    model_type='rnn',\n",
    "                                                    n_last_events=500,\n",
    "                                                    include_test_targets=True,\n",
    "                                                    train_size=0.7,\n",
    "                                                    val_size=0.15)\n",
    "\n",
    "test_tensor_dataset = EventSequenceDataPreparation(padding_value=even2idx['<PAD>'],\n",
    "                                                   event2idx=even2idx,\n",
    "                                                   input_df=grouped_df,\n",
    "                                                   sequence_column='events_sequence',\n",
    "                                                   target_column='is_churned' if churn else None,\n",
    "                                                   model_type='rnn',\n",
    "                                                   n_last_events=500,\n",
    "                                                   include_test_targets=False,\n",
    "                                                   train_size=0.7,\n",
    "                                                   val_size=0.15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_train_dataset = train_tensor_dataset['train']\n",
    "true_valid_dataset = train_tensor_dataset['val']\n",
    "true_test_dataset = train_tensor_dataset['test']\n",
    "\n",
    "# with, no - \"dummy\" - targets\n",
    "dummy_test_dataset = test_tensor_dataset['test']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f5e8942e-2568-4776-a122-8841eb4ab47e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Model init and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ac7e52ab-bcb4-4117-8914-042b89a03bf5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Model init\n",
    "config_path = '../config/nn/rnn_config.json'\n",
    "\n",
    "rnn = RNNPipeline(config_path,\n",
    "                  2 if churn else len(even2idx),\n",
    "                  even2idx['<PAD>'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a34cc397-0089-4ee6-b541-435861b87974",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "len(even2idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d62dbb22-507e-406c-a756-492d848debb4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Train\n",
    "# valid dataset is an option\n",
    "rnn.fit(true_train_dataset, true_valid_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1f8edb21-a21d-4f7c-af79-f8f1198129c7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Show best model saved location, score & best params\n",
    "print(rnn.best_model_path + '.pth')\n",
    "print(\n",
    "    f\"best score {rnn.pipeline_params['grid_search_metric']}: {rnn.best_score}\")\n",
    "rnn.best_params\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4b460caa-7815-44f4-95aa-c2599b7f6fbf",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy=nan (or other will be 'nan') because of lack of targets (dummy_test_dataset)\n",
    "\n",
    "# Use pretrained model as:\n",
    "preds = rnn.predict(\n",
    "    true_test_dataset,\n",
    "    f'{rnn.pipeline_params[\"model_artifacts_path\"]}/grid_model/RNNModel_events_task.pth')\n",
    "# Above option wil lack 'train'/'val' phases, attention weights.\n",
    "# Only phase = 'test' attention weights will be avaliable if \"save_attention_weights\" is true in config.json\n",
    "\n",
    "# OR from current run (training):\n",
    "# preds = rnn.predict(true_test_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert probabilities to 0/1 values.\n",
    "if isinstance(preds[0][0], float):\n",
    "    preds = [[int(p[0] > rnn.proba_thresold)] for p in preds]\n",
    "    print('Converted probabilities to bool.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "translated_result = [[(idx2even if not churn else idx2churn)[idx]\n",
    "                      for idx in row] for row in preds[:10]]\n",
    "print(translated_result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLFlow - registered model staging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if rnn.mlflow_config['enable'] and rnn.mlflow_config['regis_model_on_predict']:\n",
    "    registered_model_name = rnn.mlflow_manager.registered_model_name\n",
    "    registered_model_version = rnn.mlflow_manager.registered_model_version\n",
    "\n",
    "    mlflow_server = rnn.mlflow_manager.start_mlflow_server()\n",
    "    # Options are: ['None', 'Staging', 'Production', 'Archived']\n",
    "    rnn.mlflow_manager.model_staging(\n",
    "        model_name=registered_model_name,\n",
    "        model_version=registered_model_version,\n",
    "        model_stage=\"Staging\"\n",
    "    )\n",
    "    if mlflow_server:\n",
    "        os.killpg(os.getpgid(mlflow_server.pid), signal.SIGTERM)\n",
    "        print(\"\\nTerminate local MLFlow server.\")\n",
    "\n",
    "    print(f\"\\n{registered_model_name = }, {registered_model_version = }\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "099f2cc4-006a-4f3c-a6a2-bdb093908772",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Results evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_sequences, targets, seq_len = true_test_dataset.tensors\n",
    "\n",
    "padded_sequences_np = padded_sequences.squeeze(-1).numpy()\n",
    "targets_np = targets.numpy()\n",
    "\n",
    "results_df = pd.DataFrame(padded_sequences_np)\n",
    "\n",
    "\n",
    "def extract_events(row):\n",
    "    events = row[row != even2idx['<PAD>']].astype(int).tolist()\n",
    "    return events\n",
    "\n",
    "\n",
    "results_df['sequences'] = results_df.apply(extract_events, axis=1)\n",
    "results_df['seq_lengths'] = results_df['sequences'].apply(len)\n",
    "\n",
    "results_df['True_Target'] = targets_np.astype(int)\n",
    "results_df['True_Target'] = results_df['True_Target'].map(idx2even) \\\n",
    "    if not churn else results_df['True_Target'].astype(bool)\n",
    "\n",
    "results_df = results_df[['sequences', 'True_Target']]\n",
    "\n",
    "# Convert predictions\n",
    "if isinstance(preds[0], list):\n",
    "    extracted_predictions = []\n",
    "    for i, pred in enumerate(preds):\n",
    "        if targets_np[i] in pred:\n",
    "            extracted_predictions.append(targets_np[i])\n",
    "        else:\n",
    "            extracted_predictions.append(pred[0])\n",
    "    preds = extracted_predictions\n",
    "\n",
    "results_df['Predicted_Target'] = preds\n",
    "results_df['Predicted_Target'] = results_df['Predicted_Target'].map(idx2even) \\\n",
    "    if not churn else results_df['Predicted_Target'].astype(bool)\n",
    "\n",
    "results_df['Correct_Prediction'] = results_df['True_Target'] == results_df['Predicted_Target']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = results_df['Correct_Prediction'].mean()\n",
    "print(f\"accuracy: {accuracy:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f0b41008-d06e-46a3-9a6a-4648ae67ace9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "results_df['True_Target'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "992d1a64-0b0a-4079-8a41-48b949efba3b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "results_df['Predicted_Target'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "42b79d92-3622-4cd2-b95e-ed785942d7ff",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "data_melted = pd.melt(\n",
    "    results_df,\n",
    "    value_vars=['True_Target', 'Predicted_Target'],\n",
    "    var_name='Target Type',\n",
    "    value_name='Target')\n",
    "\n",
    "data_count = data_melted.groupby(\n",
    "    ['Target', 'Target Type']).size().reset_index(name='count')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c569b7cf-fad8-42a3-9203-e8e1e33e0825",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Plot True/Predicted Targets\n",
    "fig = px.bar(data_count, x='Target', y='count',\n",
    "             color='Target Type', barmode='group', text='count')\n",
    "fig.update_layout(title={\n",
    "    'text': 'Grouped Bar Chart of True and Predicted Targets',\n",
    "    'x': 0.5,\n",
    "    'xanchor': 'center'},\n",
    "    xaxis_title='Target',\n",
    "    yaxis_title='Count',\n",
    "    width=1100 if churn else 1500,\n",
    "    height=600)\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot attention weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pth = rnn.best_model_path\n",
    "\n",
    "head_index = 0\n",
    "batch_index = -4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read attention data\n",
    "if rnn.pipeline_params['save_attention_weights']:\n",
    "    data = read_rnn_attention_data(\n",
    "        file_path=f'{pth}.json',\n",
    "        phase='train',\n",
    "        head_index=head_index,\n",
    "        batch_index=batch_index)\n",
    "\n",
    "    display(data.items())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot heatmap\n",
    "if rnn.pipeline_params['save_attention_weights']:\n",
    "    plot_rnn_attention_heatmap(\n",
    "        data,\n",
    "        even2idx['<PAD>'],\n",
    "        idx2even if not churn else idx2churn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read attention data\n",
    "if rnn.pipeline_params['save_attention_weights']:\n",
    "    data = read_rnn_attention_data(\n",
    "        file_path=f'{pth}.json',\n",
    "        phase='test',\n",
    "        head_index=head_index,\n",
    "        batch_index=batch_index)\n",
    "\n",
    "    display(data.items())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot heatmap\n",
    "if rnn.pipeline_params['save_attention_weights']:\n",
    "    plot_rnn_attention_heatmap(\n",
    "        data,\n",
    "        even2idx['<PAD>'],\n",
    "        idx2even if not churn else idx2churn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if rnn.pipeline_params['save_attention_weights']:\n",
    "    sequences = get_sequences_above_weights_threshold(\n",
    "        head_data=data['heads']['0'],\n",
    "        idx2event=idx2even,\n",
    "        weights_threshold=0.55,\n",
    "        min_events=4)\n",
    "\n",
    "    display(sequences)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additionally update wheel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# local:\n",
    "# %cd /home/piotr/ggiitt/customer_analysis\n",
    "# !python setup.py bdist_wheel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "rnn_churn_or_events_pred_BigQuery_Data",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Sensitivity",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
